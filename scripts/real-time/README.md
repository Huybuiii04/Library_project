# Real-time Order Processing vá»›i Kafka CDC

## ðŸŽ¯ TÃ³m Táº¯t Quy TrÃ¬nh

**Báº¡n CHá»ˆ Cáº¦N cháº¡y 2 file Python:**
1. `order.py` - Consumer Ä‘á»c orders tá»« Kafka
2. `order_details.py` - Consumer Ä‘á»c order_details tá»« Kafka

**CDC tá»± Ä‘á»™ng cháº¡y ngáº§m!** âœ¨

```
MySQL Database (cÃ³ thay Ä‘á»•i data)
        â†“
   [AUTOMATIC CDC] â† Debezium connector Ä‘ang cháº¡y trong kafka-connect container
        â†“
Kafka Topics (mysql.project_db.orders, mysql.project_db.order_details)
        â†“
   [CHá»ˆ Cáº¦N CHáº Y 2 FILE NÃ€Y]
        â†“
  order.py + order_details.py (consumers)
        â†“
    Redis Cache â†’ Processing
```

---

## ðŸ“‹ Prerequisites

**Táº¥t cáº£ services nÃ y pháº£i Ä‘ang cháº¡y (docker compose up -d):**

1. âœ… **Redis** - localhost:6379
2. âœ… **Kafka Cluster** - 2 brokers (localhost:9093, 9095)
3. âœ… **MySQL** - localhost:3306 vá»›i binlog enabled
4. âœ… **Kafka Connect** - localhost:8083 vá»›i Debezium MySQL connector

**CDC Ä‘Ã£ Ä‘Æ°á»£c setup tá»± Ä‘á»™ng!** KhÃ´ng cáº§n cháº¡y gÃ¬ thÃªm.

---

## ðŸš€ Quick Start - CHá»ˆ 2 BÆ¯á»šC

### BÆ°á»›c 1: Verify CDC Ä‘ang cháº¡y

```bash
# Check Kafka Connect healthy
curl http://localhost:8083/

# Check Debezium connector status (pháº£i lÃ  RUNNING)
curl http://localhost:8083/connectors/mysql-source-connector/status

# Check data Ä‘Ã£ cÃ³ trong Kafka topics
docker exec kafka-broker kafka-run-class kafka.tools.GetOffsetShell \
  --broker-list localhost:9092 \
  --topic mysql.project_db.orders --time -1
# Output: mysql.project_db.orders:0:25001  â† CÃ³ data rá»“i!
```

**Náº¿u connector chÆ°a cÃ³, táº¡o 1 láº§n duy nháº¥t:**
```bash
cd scripts/real-time
curl -X POST -H "Content-Type: application/json" \
  -d "@mysql-src-connector.json" \
  http://localhost:8083/connectors
```

### BÆ°á»›c 2: Cháº¡y 2 file Python consumers

**Terminal 1 - Order Consumer:**
```bash
python scripts/real-time/order.py
```

**Terminal 2 - Order Details Consumer:**
```bash
python scripts/real-time/order_details.py
```

**XONG!** ðŸŽ‰ Há»‡ thá»‘ng Ä‘ang cháº¡y real-time processing.

---

## ðŸ“– Chi Tiáº¿t CÃ¡c Scripts

### 1. order.py - Order Consumer

**Chá»©c nÄƒng:**
- Consume messages tá»« Kafka topic: `mysql.project_db.orders`
- Äá»c CDC events (INSERT, UPDATE, DELETE tá»« MySQL orders table)
- Cache order info vÃ o Redis vá»›i key: `order:{order_id}`
- Kiá»ƒm tra xem táº¥t cáº£ order_details Ä‘Ã£ ready chÆ°a

**Auto-offset management:**
- Consumer group: `order-consumer-group`
- Auto commit offset sau khi process thÃ nh cÃ´ng
- Náº¿u crash, sáº½ resume tá»« offset cuá»‘i cÃ¹ng Ä‘Ã£ commit

**CDC Event Structure mÃ  script nháº­n Ä‘Æ°á»£c:**
```python
{
    "before": None,  # None khi INSERT
    "after": {       # Data sau khi thay Ä‘á»•i
        "id": "uuid-xxx",
        "customer_id": 123,
        "store_id": 1,
        "payment_method_id": 2,
        "num_products": 5,
        "timestamp": 1736265600000
    },
    "op": "c",  # c=create, u=update, d=delete, r=read(snapshot)
    "source": {
        "db": "project_db",
        "table": "orders",
        "file": "mysql-bin.000001",
        "pos": 12345
    }
}
```

**Cháº¡y:**
```bash
cd scripts/real-time
python order.py
```

**Output máº«u:**
```
Connected to Kafka: mysql.project_db.orders
Subscribed to topic(s): ['mysql.project_db.orders']
Processing message from partition 0, offset 12345
Order 550e8400-xxx: Saved to Redis
Order 550e8400-xxx: Waiting for 5 products...
```

---

### 2. order_details.py - Order Details Consumer

**Chá»©c nÄƒng:**
- Consume messages tá»« Kafka topic: `mysql.project_db.order_details`
- Äá»c CDC events cho order line items
- Update Redis vá»›i product info cho má»—i order
- Trigger khi Ä‘á»§ products cho 1 order

**Auto-offset management:**
- Consumer group: `order-details-consumer-group`
- Auto commit offset
- Resume tá»« last committed offset khi restart

**CDC Event Structure:**
```python
{
    "after": {
        "id": "detail-uuid-xxx",
        "order_id": "order-uuid-xxx",
        "product_id": "product-uuid",
        "quantity": 2,
        "price": 99.99
    },
    "op": "c",
    "source": {
        "db": "project_db",
        "table": "order_details"
    }
}
```

**Cháº¡y:**
```bash
cd scripts/real-time
python order_details.py
```

**Output máº«u:**
```
Connected to Kafka: mysql.project_db.order_details
Processing order_detail for order: 550e8400-xxx
Product 1/5 received for order 550e8400-xxx
Product 5/5 received - Order 550e8400-xxx COMPLETE!
```

---

## ðŸ”„ Quy TrÃ¬nh Hoáº¡t Äá»™ng Tá»•ng Thá»ƒ

### 1. CDC Background Process (Tá»° Äá»˜NG - KhÃ´ng cáº§n can thiá»‡p)

```
MySQL Operations (INSERT/UPDATE/DELETE vÃ o orders hoáº·c order_details)
              â†“
       MySQL Binlog (ROW format)
              â†“
    Debezium Connector (kafka-connect container)
    - Äá»c binlog events
    - Parse thÃ nh CDC format
    - Publish vÃ o Kafka topics
              â†“
       Kafka Topics:
       - mysql.project_db.orders
       - mysql.project_db.order_details
```

**Debezium connector cháº¡y 24/7 trong background!**
- Container: `kafka-connect`
- Port: 8083
- Status: Check vá»›i `curl http://localhost:8083/connectors/mysql-source-connector/status`

### 2. Consumer Processing (CHá»ˆ Cáº¦N CHáº Y 2 FILE PYTHON)

```
Kafka Topics (cÃ³ sáºµn data tá»« CDC)
       â†“
   order.py â† Consume tá»« mysql.project_db.orders
       â†“
   Redis: order:{id} = {customer_id, num_products, ...}
       â†“
   Chá» order_details...
       â†“
   order_details.py â† Consume tá»« mysql.project_db.order_details
       â†“
   Redis: order:{id}:products = [product1, product2, ...]
       â†“
   Khi Ä‘á»§ products â†’ Trigger processing
       â†“
   Complete! âœ…
```

---

## ðŸ§ª Test Real-Time CDC

### Scenario 1: Insert New Order

**BÆ°á»›c 1: Cháº¡y 2 consumers (2 terminals riÃªng biá»‡t)**
```bash
# Terminal 1
python scripts/real-time/order.py

# Terminal 2
python scripts/real-time/order_details.py
```

**BÆ°á»›c 2: Insert order má»›i vÃ o MySQL**
```bash
docker exec -i mysql-db mysql -uadmin -padmin project_db -e \
  "INSERT INTO orders (id, customer_id, store_id, payment_method_id, num_products) 
   VALUES (UUID(), 123, 1, 1, 3);"
```

**BÆ°á»›c 3: Quan sÃ¡t output**
- `order.py` sáº½ ngay láº­p tá»©c nháº­n CDC event vÃ  log
- Order Ä‘Æ°á»£c cache vÃ o Redis
- Chá» 3 products...

**BÆ°á»›c 4: Insert order_details**
```bash
docker exec -i mysql-db mysql -uadmin -padmin project_db -e \
  "SET @order_id = (SELECT id FROM orders ORDER BY timestamp DESC LIMIT 1);
   INSERT INTO order_details (id, order_id, product_id, quantity, price) VALUES
   (UUID(), @order_id, UUID(), 1, 10.00),
   (UUID(), @order_id, UUID(), 2, 20.00),
   (UUID(), @order_id, UUID(), 1, 15.00);"
```

**BÆ°á»›c 5: Quan sÃ¡t completion**
- `order_details.py` nháº­n 3 CDC events
- Counter: 1/3, 2/3, 3/3
- Khi Ä‘á»§ 3 â†’ Trigger processing â†’ COMPLETE!

### Scenario 2: Update Order

```bash
# Update existing order
docker exec -i mysql-db mysql -uadmin -padmin project_db -e \
  "UPDATE orders SET payment_method_id = 2 
   WHERE id = (SELECT id FROM (SELECT id FROM orders LIMIT 1) AS tmp);"
```

**CDC Event:**
```python
{
    "before": {"payment_method_id": 1, ...},  # Old value
    "after": {"payment_method_id": 2, ...},   # New value
    "op": "u"  # Update operation
}
```

`order.py` sáº½ nháº­n event vÃ  update Redis cache.

### Scenario 3: Delete Order

```bash
docker exec -i mysql-db mysql -uadmin -padmin project_db -e \
  "DELETE FROM order_details WHERE order_id = 'some-uuid';
   DELETE FROM orders WHERE id = 'some-uuid';"
```

**CDC Event:**
```python
{
    "before": {"id": "some-uuid", ...},  # Deleted record
    "after": None,  # No data after delete
    "op": "d"  # Delete operation
}
```

Consumers cÃ³ thá»ƒ handle delete events Ä‘á»ƒ cleanup Redis.

---

## ðŸ› Troubleshooting

### Issue 1: Consumers khÃ´ng nháº­n Ä‘Æ°á»£c messages

**Check 1: CDC connector cÃ³ Ä‘ang cháº¡y?**
```bash
curl http://localhost:8083/connectors/mysql-source-connector/status
# Pháº£i tháº¥y: "state": "RUNNING"
```

**Check 2: Kafka topics cÃ³ data?**
```bash
docker exec kafka-broker kafka-run-class kafka.tools.GetOffsetShell \
  --broker-list localhost:9092 \
  --topic mysql.project_db.orders --time -1
# Pháº£i tháº¥y offset > 0
```

**Check 3: Consumer group cÃ³ active?**
```bash
docker exec kafka-broker kafka-consumer-groups \
  --bootstrap-server localhost:9092 \
  --describe --group order-consumer-group
```

**Fix:** Restart Debezium connector
```bash
curl -X POST http://localhost:8083/connectors/mysql-source-connector/restart
```

---

### Issue 2: Consumers cháº¡y cháº­m (consumer lag)

**Check lag:**
```bash
docker exec kafka-broker kafka-consumer-groups \
  --bootstrap-server localhost:9092 \
  --describe --group order-consumer-group
```

**Fix options:**
1. Increase consumers (run multiple instances)
2. Increase batch size trong Python code
3. Optimize Redis operations (pipeline, batch writes)

---

### Issue 3: Redis connection errors

**Check Redis:**
```bash
docker ps | findstr redis
docker exec redis-cache redis-cli ping
# Pháº£i tráº£ vá»: PONG
```

**Test connection:**
```bash
docker exec redis-cache redis-cli
> SET test "hello"
> GET test
> DEL test
```

---

### Issue 4: CDC khÃ´ng capture changes má»›i

**Check MySQL binlog:**
```bash
docker exec mysql-db mysql -uadmin -padmin -e "SHOW MASTER STATUS;"
# File vÃ  Position pháº£i thay Ä‘á»•i sau INSERT/UPDATE
```

**Check connector offset:**
```bash
# View last processed binlog position
docker exec kafka-broker kafka-console-consumer \
  --bootstrap-server localhost:9092 \
  --topic connect-offsets \
  --from-beginning --max-messages 10
```

**Fix:** Force snapshot
```bash
# Delete connector
curl -X DELETE http://localhost:8083/connectors/mysql-source-connector

# Recreate (sáº½ lÃ m snapshot láº¡i)
curl -X POST -H "Content-Type: application/json" \
  -d "@mysql-src-connector.json" \
  http://localhost:8083/connectors
```

---

## ðŸ“Š Monitoring Commands

### Check Kafka Topics
```bash
# List all topics
docker exec kafka-broker kafka-topics --bootstrap-server localhost:9092 --list

# Describe specific topic
docker exec kafka-broker kafka-topics --bootstrap-server localhost:9092 \
  --describe --topic mysql.project_db.orders
```

### View Raw Messages
```bash
# Consume from beginning
docker exec kafka-broker kafka-console-consumer \
  --bootstrap-server localhost:9092 \
  --topic mysql.project_db.orders \
  --from-beginning --max-messages 5

# Consume latest messages only
docker exec kafka-broker kafka-console-consumer \
  --bootstrap-server localhost:9092 \
  --topic mysql.project_db.orders \
  --offset latest --partition 0
```

### Check Redis Data
```bash
# Connect to Redis CLI
docker exec -it redis-cache redis-cli

# List all order keys
> KEYS order:*

# Get specific order
> GET order:550e8400-xxx

# Check products for order
> LRANGE order:550e8400-xxx:products 0 -1

# Count total orders in cache
> DBSIZE
```

### Monitor Consumer Groups
```bash
# List all consumer groups
docker exec kafka-broker kafka-consumer-groups \
  --bootstrap-server localhost:9092 --list

# Get details for specific group
docker exec kafka-broker kafka-consumer-groups \
  --bootstrap-server localhost:9092 \
  --describe --group order-consumer-group \
  --verbose
```

---

## ðŸ“ Summary - Quy TrÃ¬nh Cháº¡y

### Tá»° Äá»˜NG (ÄÃ£ setup, cháº¡y background):
1. âœ… MySQL binlog enabled
2. âœ… Kafka Connect vá»›i Debezium connector RUNNING
3. âœ… CDC tá»± Ä‘á»™ng capture changes â†’ Kafka topics
4. âœ… 25,000+ orders + 47,000+ order_details Ä‘Ã£ cÃ³ trong Kafka

### CHá»ˆ Cáº¦N LÃ€M (2 commands):
```bash
# Terminal 1
python scripts/real-time/order.py

# Terminal 2  
python scripts/real-time/order_details.py
```

### Káº¿t Quáº£:
- âœ… Real-time processing má»i thay Ä‘á»•i trong MySQL
- âœ… Auto-resume tá»« last offset khi restart
- âœ… Redis cache Ä‘á»“ng bá»™ vá»›i database
- âœ… Scalable (cháº¡y nhiá»u consumers cÃ¹ng lÃºc)

---

**KhÃ´ng cáº§n cháº¡y gÃ¬ khÃ¡c!** CDC Ä‘Ã£ tá»± Ä‘á»™ng hoáº¡t Ä‘á»™ng 24/7. ðŸš€
python order.py

### Start Order Details Tracker (3 workers)
```bash
python scripts\real-time\order_details.py
```

This script:
- Consumes from `mysql.project_db.order_details` topic
- Caches product IDs in Redis
- Checks if order is complete

## How It Works

1. When an order is created in MySQL, Debezium captures it and sends to Kafka topic `mysql.project_db.orders`
2. `order.py` consumes this and stores order info (customer_id, payment_method_id, num_products) in Redis
3. When order details are created, they go to `mysql.project_db.order_details` topic
4. `order_details.py` consumes and stores product IDs in Redis
5. Both scripts call `check_and_trigger()` to verify if order is complete
6. When complete, a consolidated message is sent to `order_ready_for_checking` topic

## Redis Keys Structure

```
order_info:{order_id} -> Hash
  - customer_id
  - payment_method_id
  - num_products

ordered_products:{order_id} -> Set
  - product_id_1
  - product_id_2
  - ...

order_status:{order_id} -> String
  - "checking" (when order is being processed)
```

## Monitoring

- **Kafka UI**: http://localhost:8084
- **Redis**: Use redis-cli or connect via redis client
- **Logs**: Check `logs/real-time.log`

## Troubleshooting

### Connector not running
```bash
# Restart connector
curl -X POST http://localhost:8083/connectors/mysql-source-connector/restart

# Check logs
docker logs kafka-connect
```

### No messages in Kafka
```bash
# Check topics
docker exec kafka-broker kafka-topics --bootstrap-server localhost:9092 --list

# Check messages
docker exec kafka-broker kafka-console-consumer --bootstrap-server localhost:9092 --topic mysql.project_db.orders --from-beginning --max-messages 10
```

### Redis connection error
```bash
# Check Redis
docker exec redis-cache redis-cli ping

# Check Redis keys
docker exec redis-cache redis-cli --scan --pattern "order*"
```
